{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfb5443",
   "metadata": {
    "papermill": {
     "duration": 0.008539,
     "end_time": "2024-10-04T07:23:24.330067",
     "exception": false,
     "start_time": "2024-10-04T07:23:24.321528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Wagtail_Gemma_Blog_social_card_te.2e16d0ba.fill-1200x600.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d1b4d",
   "metadata": {
    "papermill": {
     "duration": 0.007567,
     "end_time": "2024-10-04T07:23:24.345446",
     "exception": false,
     "start_time": "2024-10-04T07:23:24.337879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hello\n",
    "Gemma 2 will be fine-tunned using LoRA for greetings in different languages and cultures. In this notebook our focus will be **Hello** greeting. Keras will be used with Gemma 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ec2ac",
   "metadata": {
    "papermill": {
     "duration": 0.008378,
     "end_time": "2024-10-04T07:23:24.361419",
     "exception": false,
     "start_time": "2024-10-04T07:23:24.353041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4a7848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:23:24.378013Z",
     "iopub.status.busy": "2024-10-04T07:23:24.377676Z",
     "iopub.status.idle": "2024-10-04T07:24:01.873226Z",
     "shell.execute_reply": "2024-10-04T07:24:01.872196Z"
    },
    "papermill": {
     "duration": 37.50688,
     "end_time": "2024-10-04T07:24:01.875822",
     "exception": false,
     "start_time": "2024-10-04T07:23:24.368942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "!pip install -q -U kagglehub --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88033566",
   "metadata": {
    "papermill": {
     "duration": 0.007637,
     "end_time": "2024-10-04T07:24:01.891571",
     "exception": false,
     "start_time": "2024-10-04T07:24:01.883934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc0508f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:24:01.908557Z",
     "iopub.status.busy": "2024-10-04T07:24:01.908190Z",
     "iopub.status.idle": "2024-10-04T07:24:15.895031Z",
     "shell.execute_reply": "2024-10-04T07:24:15.894246Z"
    },
    "papermill": {
     "duration": 13.998,
     "end_time": "2024-10-04T07:24:15.897270",
     "exception": false,
     "start_time": "2024-10-04T07:24:01.899270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"\"\n",
    "import keras\n",
    "import keras_nlp\n",
    "import kagglehub\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas() # progress bar for pandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248b118",
   "metadata": {
    "papermill": {
     "duration": 0.007524,
     "end_time": "2024-10-04T07:24:15.912711",
     "exception": false,
     "start_time": "2024-10-04T07:24:15.905187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82708275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:24:15.929314Z",
     "iopub.status.busy": "2024-10-04T07:24:15.928829Z",
     "iopub.status.idle": "2024-10-04T07:24:15.933738Z",
     "shell.execute_reply": "2024-10-04T07:24:15.932908Z"
    },
    "papermill": {
     "duration": 0.015345,
     "end_time": "2024-10-04T07:24:15.935617",
     "exception": false,
     "start_time": "2024-10-04T07:24:15.920272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 42\n",
    "    dataset_path = \"/kaggle/input/cultural-greetings\"\n",
    "    preset = \"gemma2_2b_en\" # name of pretrained Gemma 2\n",
    "    sequence_length = 512 # max size of input sequence for training\n",
    "    batch_size = 1 # size of the input batch in training\n",
    "    lora_rank = 4 # rank for LoRA, higher means more trainable parameters\n",
    "    learning_rate=8e-5 # learning rate used in train\n",
    "    epochs = 10 # number of epochs to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e261b183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:24:15.952484Z",
     "iopub.status.busy": "2024-10-04T07:24:15.951988Z",
     "iopub.status.idle": "2024-10-04T07:24:15.956278Z",
     "shell.execute_reply": "2024-10-04T07:24:15.955426Z"
    },
    "papermill": {
     "duration": 0.014431,
     "end_time": "2024-10-04T07:24:15.958044",
     "exception": false,
     "start_time": "2024-10-04T07:24:15.943613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5ae7c",
   "metadata": {
    "papermill": {
     "duration": 0.007315,
     "end_time": "2024-10-04T07:24:15.972999",
     "exception": false,
     "start_time": "2024-10-04T07:24:15.965684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87146634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:24:15.990247Z",
     "iopub.status.busy": "2024-10-04T07:24:15.989986Z",
     "iopub.status.idle": "2024-10-04T07:24:16.016772Z",
     "shell.execute_reply": "2024-10-04T07:24:16.015930Z"
    },
    "papermill": {
     "duration": 0.038158,
     "end_time": "2024-10-04T07:24:16.018771",
     "exception": false,
     "start_time": "2024-10-04T07:24:15.980613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Greetings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Western</td>\n",
       "      <td>Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Hola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "      <td>Bonjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>Hallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Ciao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language   Culture Greetings\n",
       "0  English   Western     Hello\n",
       "1  Spanish  Hispanic      Hola\n",
       "2   French    French   Bonjour\n",
       "3   German  Germanic     Hallo\n",
       "4  Italian   Italian      Ciao"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{Config.dataset_path}/train_hello.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf8661",
   "metadata": {
    "papermill": {
     "duration": 0.007698,
     "end_time": "2024-10-04T07:24:16.034540",
     "exception": false,
     "start_time": "2024-10-04T07:24:16.026842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Template Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57fd3be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:24:16.051646Z",
     "iopub.status.busy": "2024-10-04T07:24:16.050952Z",
     "iopub.status.idle": "2024-10-04T07:24:16.060281Z",
     "shell.execute_reply": "2024-10-04T07:24:16.059526Z"
    },
    "papermill": {
     "duration": 0.019727,
     "end_time": "2024-10-04T07:24:16.062119",
     "exception": false,
     "start_time": "2024-10-04T07:24:16.042392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\\n\\nLanguage:\\n{Language}\\n\\nCulture:\\n{Culture}\\n\\nGreetings:\\n{Greetings}\"\n",
    "df[\"prompt\"] = df.apply(lambda row: template.format(Language=row.Language,\n",
    "                                                             Culture=row.Culture,\n",
    "                                                             Greetings=row.Greetings), axis=1)\n",
    "data = df.prompt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f5b7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:24:16.078908Z",
     "iopub.status.busy": "2024-10-04T07:24:16.078650Z",
     "iopub.status.idle": "2024-10-04T07:24:16.084144Z",
     "shell.execute_reply": "2024-10-04T07:24:16.083495Z"
    },
    "papermill": {
     "duration": 0.015999,
     "end_time": "2024-10-04T07:24:16.085990",
     "exception": false,
     "start_time": "2024-10-04T07:24:16.069991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Language\", \"Culture\", \"Greetings\"], [\"blue\", \"red\", \"green\"]):\n",
    "        text = text.replace(f\"\\n\\n{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8716ab03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:24:16.102744Z",
     "iopub.status.busy": "2024-10-04T07:24:16.102467Z",
     "iopub.status.idle": "2024-10-04T07:25:20.359858Z",
     "shell.execute_reply": "2024-10-04T07:25:20.359033Z"
    },
    "papermill": {
     "duration": 64.268288,
     "end_time": "2024-10-04T07:25:20.362048",
     "exception": false,
     "start_time": "2024-10-04T07:24:16.093760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "gemma_causal_lm = keras_nlp.models.GemmaCausalLM.from_preset(Config.preset)\n",
    "\n",
    "#The code creates a causal language model named gemma_causal_lm using a \n",
    "#pre-defined configuration specified in Config.preset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c88528a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:25:20.380408Z",
     "iopub.status.busy": "2024-10-04T07:25:20.379623Z",
     "iopub.status.idle": "2024-10-04T07:25:20.410846Z",
     "shell.execute_reply": "2024-10-04T07:25:20.409983Z"
    },
    "papermill": {
     "duration": 0.042492,
     "end_time": "2024-10-04T07:25:20.412837",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.370345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_causal_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea853244",
   "metadata": {
    "papermill": {
     "duration": 0.008813,
     "end_time": "2024-10-04T07:25:20.430935",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.422122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gemma Cultural Greetings Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbcb242c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:25:20.450794Z",
     "iopub.status.busy": "2024-10-04T07:25:20.450454Z",
     "iopub.status.idle": "2024-10-04T07:25:20.456420Z",
     "shell.execute_reply": "2024-10-04T07:25:20.455541Z"
    },
    "papermill": {
     "duration": 0.018165,
     "end_time": "2024-10-04T07:25:20.458470",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.440305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GemmaCG:\n",
    "    def __init__(self, max_length=512):\n",
    "        self.max_length = max_length\n",
    "        self.prompt = template\n",
    "        self.gemma_causal_lm = gemma_causal_lm\n",
    "        \n",
    "    def query(self, Language, Culture):\n",
    "        response = self.gemma_causal_lm.generate(\n",
    "            self.prompt.format(\n",
    "                Language=Language,\n",
    "                Culture=Culture,\n",
    "                Greetings=\"\"), \n",
    "            max_length=self.max_length)\n",
    "        display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd9d66",
   "metadata": {
    "papermill": {
     "duration": 0.008967,
     "end_time": "2024-10-04T07:25:20.476585",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.467618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b259d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:25:20.496767Z",
     "iopub.status.busy": "2024-10-04T07:25:20.495718Z",
     "iopub.status.idle": "2024-10-04T07:25:20.654091Z",
     "shell.execute_reply": "2024-10-04T07:25:20.653210Z"
    },
    "papermill": {
     "duration": 0.170795,
     "end_time": "2024-10-04T07:25:20.656460",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.485665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_ids': Array([[    2,   109, 14357, ...,     0,     0,     0],\n",
      "       [    2,   109, 14357, ...,     0,     0,     0]], dtype=int32), 'padding_mask': Array([[ True,  True,  True, ..., False, False, False],\n",
      "       [ True,  True,  True, ..., False, False, False]], dtype=bool)} [[   109  14357 235292 ...      0      0      0]\n",
      " [   109  14357 235292 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "x, y, sample_weight = gemma_causal_lm.preprocessor(data[0:2])\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb5cae",
   "metadata": {
    "papermill": {
     "duration": 0.009125,
     "end_time": "2024-10-04T07:25:20.674990",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.665865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `gemma_causal_lm.preprocessor(data[0:2])`: This line calls the `preprocessor` method of the `gemma_causal_lm` object, passing the first two elements of the `data` list as input. The `preprocessor` method is likely responsible for preprocessing the input data into a format suitable for the language model. It might involve tasks such as tokenization, normalization, and encoding.\n",
    "- `x, y = gemma_causal_lm.preprocessor(data[0:2])`: This line unpacks the return value of the `preprocessor` method into two variables, `x` and `y`. The `x` variable likely represents the input features to the model, while the `y` variable represents the corresponding target labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88362f2",
   "metadata": {
    "papermill": {
     "duration": 0.008902,
     "end_time": "2024-10-04T07:25:20.693029",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.684127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-Tuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863d9d2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:25:20.712697Z",
     "iopub.status.busy": "2024-10-04T07:25:20.712328Z",
     "iopub.status.idle": "2024-10-04T07:25:20.978075Z",
     "shell.execute_reply": "2024-10-04T07:25:20.977040Z"
    },
    "papermill": {
     "duration": 0.278193,
     "end_time": "2024-10-04T07:25:20.980434",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.702241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5936cc",
   "metadata": {
    "papermill": {
     "duration": 0.009074,
     "end_time": "2024-10-04T07:25:20.999085",
     "exception": false,
     "start_time": "2024-10-04T07:25:20.990011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)`: This line calls the `enable_lora` method of the `backbone` attribute of the `gemma_causal_lm` object, passing the `rank` parameter with the value `Config.lora_rank`\n",
    "- This code enables Low-Rank Adaptation (LoRA) for the `backbone` component of the `gemma_causal_lm` model. LoRA is a technique that allows for fine-tuning a pre-trained model on a smaller dataset while keeping the original model parameters mostly frozen. This can be beneficial in scenarios where the available training data is limited or the model is very large.\n",
    "- The `rank` parameter specifies the rank of the low-rank matrices that will be introduced into the model. A higher rank generally allows for more flexibility but also increases the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01ffdbf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:25:21.019110Z",
     "iopub.status.busy": "2024-10-04T07:25:21.018395Z",
     "iopub.status.idle": "2024-10-04T07:25:21.048949Z",
     "shell.execute_reply": "2024-10-04T07:25:21.048083Z"
    },
    "papermill": {
     "duration": 0.042762,
     "end_time": "2024-10-04T07:25:21.050931",
     "exception": false,
     "start_time": "2024-10-04T07:25:21.008169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_causal_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651a4cd",
   "metadata": {
    "papermill": {
     "duration": 0.010051,
     "end_time": "2024-10-04T07:25:21.071427",
     "exception": false,
     "start_time": "2024-10-04T07:25:21.061376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a4249d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:25:21.093720Z",
     "iopub.status.busy": "2024-10-04T07:25:21.092976Z",
     "iopub.status.idle": "2024-10-04T07:39:42.427911Z",
     "shell.execute_reply": "2024-10-04T07:39:42.426936Z"
    },
    "papermill": {
     "duration": 861.348177,
     "end_time": "2024-10-04T07:39:42.429864",
     "exception": false,
     "start_time": "2024-10-04T07:25:21.081687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 985ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.5788\n",
      "Epoch 2/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 806ms/step - loss: 0.0249 - sparse_categorical_accuracy: 0.8503\n",
      "Epoch 3/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.8952\n",
      "Epoch 4/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0175 - sparse_categorical_accuracy: 0.8998\n",
      "Epoch 5/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9041\n",
      "Epoch 6/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9100\n",
      "Epoch 7/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9191\n",
      "Epoch 8/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0125 - sparse_categorical_accuracy: 0.9298\n",
      "Epoch 9/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 10/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9413\n"
     ]
    }
   ],
   "source": [
    "#set sequence length cf. config (512)\n",
    "gemma_causal_lm.preprocessor.sequence_length = Config.sequence_length \n",
    "\n",
    "# Compile the model with loss, optimizer, and metric\n",
    "gemma_causal_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=Config.learning_rate),\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train model\n",
    "gemma_causal_lm.fit(data, epochs=Config.epochs, batch_size=Config.batch_size)\n",
    "\n",
    "gemma_cg = GemmaCG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb504b4",
   "metadata": {
    "papermill": {
     "duration": 0.072255,
     "end_time": "2024-10-04T07:39:42.612488",
     "exception": false,
     "start_time": "2024-10-04T07:39:42.540233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Known Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05e7e3be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:39:42.765544Z",
     "iopub.status.busy": "2024-10-04T07:39:42.764861Z",
     "iopub.status.idle": "2024-10-04T07:39:42.773325Z",
     "shell.execute_reply": "2024-10-04T07:39:42.772373Z"
    },
    "papermill": {
     "duration": 0.090011,
     "end_time": "2024-10-04T07:39:42.775587",
     "exception": false,
     "start_time": "2024-10-04T07:39:42.685576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language                                               Spanish\n",
       "Culture                                               Hispanic\n",
       "Greetings                                                 Hola\n",
       "prompt       \\n\\nLanguage:\\nSpanish\\n\\nCulture:\\nHispanic\\n...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "132bce16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:39:42.926122Z",
     "iopub.status.busy": "2024-10-04T07:39:42.925824Z",
     "iopub.status.idle": "2024-10-04T07:39:57.872317Z",
     "shell.execute_reply": "2024-10-04T07:39:57.871335Z"
    },
    "papermill": {
     "duration": 15.021917,
     "end_time": "2024-10-04T07:39:57.874437",
     "exception": false,
     "start_time": "2024-10-04T07:39:42.852520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Language:</font>**\n",
       "Spanish\n",
       "\n",
       "**<font color='red'>Culture:</font>**\n",
       "Hispanic\n",
       "\n",
       "**<font color='green'>Greetings:</font>**\n",
       "Hola"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = df.iloc[1]\n",
    "gemma_cg.query(row.Language,row.Culture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac795bed",
   "metadata": {
    "papermill": {
     "duration": 0.07227,
     "end_time": "2024-10-04T07:39:58.019559",
     "exception": false,
     "start_time": "2024-10-04T07:39:57.947289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01e3bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:39:58.165243Z",
     "iopub.status.busy": "2024-10-04T07:39:58.164619Z",
     "iopub.status.idle": "2024-10-04T07:39:58.546562Z",
     "shell.execute_reply": "2024-10-04T07:39:58.545634Z"
    },
    "papermill": {
     "duration": 0.457016,
     "end_time": "2024-10-04T07:39:58.548481",
     "exception": false,
     "start_time": "2024-10-04T07:39:58.091465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Language:</font>**\n",
       "Malay\n",
       "\n",
       "**<font color='red'>Culture:</font>**\n",
       "Malay\n",
       "\n",
       "**<font color='green'>Greetings:</font>**\n",
       "Salam"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Language = \"Malay\"\n",
    "Culture = \"Malay\"\n",
    "gemma_cg.query(Language,Culture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8a19284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:39:58.697000Z",
     "iopub.status.busy": "2024-10-04T07:39:58.696163Z",
     "iopub.status.idle": "2024-10-04T07:40:31.226376Z",
     "shell.execute_reply": "2024-10-04T07:40:31.225300Z"
    },
    "papermill": {
     "duration": 32.606358,
     "end_time": "2024-10-04T07:40:31.229034",
     "exception": false,
     "start_time": "2024-10-04T07:39:58.622676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preset_dir = \".\\gemma2_2b_en_cultural_greetings\"\n",
    "gemma_causal_lm.save_to_preset(preset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d32aa",
   "metadata": {
    "papermill": {
     "duration": 0.079203,
     "end_time": "2024-10-04T07:40:45.669215",
     "exception": false,
     "start_time": "2024-10-04T07:40:45.590012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Acknowledgements:\n",
    "\n",
    "Gabriel Preda https://www.kaggle.com/code/gpreda/fine-tuning-gemma-2-model-using-lora-and-keras/notebook\n",
    "\n",
    "Marilia Prata https://www.kaggle.com/code/mpwolke/global-communication-gemma2keras"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9690815,
     "sourceId": 85416,
     "sourceType": "competition"
    },
    {
     "datasetId": 5810993,
     "sourceId": 9544562,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72244,
     "sourceId": 85984,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1047.145243,
   "end_time": "2024-10-04T07:40:48.748773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-04T07:23:21.603530",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
