{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b97338",
   "metadata": {
    "papermill": {
     "duration": 0.008724,
     "end_time": "2024-10-04T12:55:02.616439",
     "exception": false,
     "start_time": "2024-10-04T12:55:02.607715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Wagtail_Gemma_Blog_social_card_te.2e16d0ba.fill-1200x600.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab5349b",
   "metadata": {
    "papermill": {
     "duration": 0.007621,
     "end_time": "2024-10-04T12:55:02.631939",
     "exception": false,
     "start_time": "2024-10-04T12:55:02.624318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How Are You\n",
    "Gemma 2 will be fine-tunned using LoRA for greetings in different languages and cultures. In this notebook our focus will be **How Are You** greeting. Keras will be used with Gemma 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3239b",
   "metadata": {
    "papermill": {
     "duration": 0.00868,
     "end_time": "2024-10-04T12:55:02.648473",
     "exception": false,
     "start_time": "2024-10-04T12:55:02.639793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21624e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:55:02.665788Z",
     "iopub.status.busy": "2024-10-04T12:55:02.664970Z",
     "iopub.status.idle": "2024-10-04T12:55:39.923645Z",
     "shell.execute_reply": "2024-10-04T12:55:39.922476Z"
    },
    "papermill": {
     "duration": 37.269947,
     "end_time": "2024-10-04T12:55:39.926034",
     "exception": false,
     "start_time": "2024-10-04T12:55:02.656087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "!pip install -q -U kagglehub --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcedb5ec",
   "metadata": {
    "papermill": {
     "duration": 0.007787,
     "end_time": "2024-10-04T12:55:39.941951",
     "exception": false,
     "start_time": "2024-10-04T12:55:39.934164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e294f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:55:39.959204Z",
     "iopub.status.busy": "2024-10-04T12:55:39.958849Z",
     "iopub.status.idle": "2024-10-04T12:55:53.533258Z",
     "shell.execute_reply": "2024-10-04T12:55:53.532264Z"
    },
    "papermill": {
     "duration": 13.585733,
     "end_time": "2024-10-04T12:55:53.535636",
     "exception": false,
     "start_time": "2024-10-04T12:55:39.949903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"\"\n",
    "import keras\n",
    "import keras_nlp\n",
    "import kagglehub\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas() # progress bar for pandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70943a",
   "metadata": {
    "papermill": {
     "duration": 0.007643,
     "end_time": "2024-10-04T12:55:53.551341",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.543698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6084ecaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:55:53.568089Z",
     "iopub.status.busy": "2024-10-04T12:55:53.567595Z",
     "iopub.status.idle": "2024-10-04T12:55:53.572598Z",
     "shell.execute_reply": "2024-10-04T12:55:53.571751Z"
    },
    "papermill": {
     "duration": 0.015569,
     "end_time": "2024-10-04T12:55:53.574571",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.559002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 42\n",
    "    dataset_path = \"/kaggle/input/cultural-greetings\"\n",
    "    preset = \"gemma2_2b_en\" # name of pretrained Gemma 2\n",
    "    sequence_length = 512 # max size of input sequence for training\n",
    "    batch_size = 1 # size of the input batch in training\n",
    "    lora_rank = 4 # rank for LoRA, higher means more trainable parameters\n",
    "    learning_rate=8e-5 # learning rate used in train\n",
    "    epochs = 10 # number of epochs to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a929bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:55:53.591436Z",
     "iopub.status.busy": "2024-10-04T12:55:53.590701Z",
     "iopub.status.idle": "2024-10-04T12:55:53.595330Z",
     "shell.execute_reply": "2024-10-04T12:55:53.594499Z"
    },
    "papermill": {
     "duration": 0.014873,
     "end_time": "2024-10-04T12:55:53.597236",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.582363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c47e8",
   "metadata": {
    "papermill": {
     "duration": 0.007412,
     "end_time": "2024-10-04T12:55:53.612351",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.604939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4e3498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:55:53.628974Z",
     "iopub.status.busy": "2024-10-04T12:55:53.628710Z",
     "iopub.status.idle": "2024-10-04T12:55:53.656062Z",
     "shell.execute_reply": "2024-10-04T12:55:53.655242Z"
    },
    "papermill": {
     "duration": 0.038019,
     "end_time": "2024-10-04T12:55:53.658096",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.620077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Greetings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Western</td>\n",
       "      <td>How are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>¿Cómo estás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "      <td>Comment ça va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>Wie geht's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Come stai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language   Culture      Greetings\n",
       "0  English   Western    How are you\n",
       "1  Spanish  Hispanic    ¿Cómo estás\n",
       "2   French    French  Comment ça va\n",
       "3   German  Germanic     Wie geht's\n",
       "4  Italian   Italian      Come stai"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{Config.dataset_path}/train_how_are_you.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1941a20e",
   "metadata": {
    "papermill": {
     "duration": 0.007668,
     "end_time": "2024-10-04T12:55:53.674103",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.666435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Template Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c8b649f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:55:53.690887Z",
     "iopub.status.busy": "2024-10-04T12:55:53.690606Z",
     "iopub.status.idle": "2024-10-04T12:55:53.700207Z",
     "shell.execute_reply": "2024-10-04T12:55:53.699352Z"
    },
    "papermill": {
     "duration": 0.019972,
     "end_time": "2024-10-04T12:55:53.702031",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.682059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\\n\\nLanguage:\\n{Language}\\n\\nCulture:\\n{Culture}\\n\\nGreetings:\\n{Greetings}\"\n",
    "df[\"prompt\"] = df.apply(lambda row: template.format(Language=row.Language,\n",
    "                                                             Culture=row.Culture,\n",
    "                                                             Greetings=row.Greetings), axis=1)\n",
    "data = df.prompt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8189ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:55:53.718730Z",
     "iopub.status.busy": "2024-10-04T12:55:53.718445Z",
     "iopub.status.idle": "2024-10-04T12:55:53.723044Z",
     "shell.execute_reply": "2024-10-04T12:55:53.722284Z"
    },
    "papermill": {
     "duration": 0.015016,
     "end_time": "2024-10-04T12:55:53.724809",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.709793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Language\", \"Culture\", \"Greetings\"], [\"blue\", \"red\", \"green\"]):\n",
    "        text = text.replace(f\"\\n\\n{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fdf13f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:55:53.741455Z",
     "iopub.status.busy": "2024-10-04T12:55:53.741166Z",
     "iopub.status.idle": "2024-10-04T12:57:09.564586Z",
     "shell.execute_reply": "2024-10-04T12:57:09.563570Z"
    },
    "papermill": {
     "duration": 75.834322,
     "end_time": "2024-10-04T12:57:09.566908",
     "exception": false,
     "start_time": "2024-10-04T12:55:53.732586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "gemma_causal_lm = keras_nlp.models.GemmaCausalLM.from_preset(Config.preset)\n",
    "\n",
    "#The code creates a causal language model named gemma_causal_lm using a \n",
    "#pre-defined configuration specified in Config.preset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1087f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:57:09.584652Z",
     "iopub.status.busy": "2024-10-04T12:57:09.584333Z",
     "iopub.status.idle": "2024-10-04T12:57:09.615660Z",
     "shell.execute_reply": "2024-10-04T12:57:09.614820Z"
    },
    "papermill": {
     "duration": 0.042509,
     "end_time": "2024-10-04T12:57:09.617742",
     "exception": false,
     "start_time": "2024-10-04T12:57:09.575233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_causal_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2693da",
   "metadata": {
    "papermill": {
     "duration": 0.008903,
     "end_time": "2024-10-04T12:57:09.635859",
     "exception": false,
     "start_time": "2024-10-04T12:57:09.626956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gemma Cultural Greetings Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5254cc2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:57:09.655058Z",
     "iopub.status.busy": "2024-10-04T12:57:09.654777Z",
     "iopub.status.idle": "2024-10-04T12:57:09.660611Z",
     "shell.execute_reply": "2024-10-04T12:57:09.659809Z"
    },
    "papermill": {
     "duration": 0.018013,
     "end_time": "2024-10-04T12:57:09.662811",
     "exception": false,
     "start_time": "2024-10-04T12:57:09.644798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GemmaCG:\n",
    "    def __init__(self, max_length=512):\n",
    "        self.max_length = max_length\n",
    "        self.prompt = template\n",
    "        self.gemma_causal_lm = gemma_causal_lm\n",
    "        \n",
    "    def query(self, Language, Culture):\n",
    "        response = self.gemma_causal_lm.generate(\n",
    "            self.prompt.format(\n",
    "                Language=Language,\n",
    "                Culture=Culture,\n",
    "                Greetings=\"\"), \n",
    "            max_length=self.max_length)\n",
    "        display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d2a4a",
   "metadata": {
    "papermill": {
     "duration": 0.00881,
     "end_time": "2024-10-04T12:57:09.680539",
     "exception": false,
     "start_time": "2024-10-04T12:57:09.671729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d5fda8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:57:09.699726Z",
     "iopub.status.busy": "2024-10-04T12:57:09.699453Z",
     "iopub.status.idle": "2024-10-04T12:57:09.863241Z",
     "shell.execute_reply": "2024-10-04T12:57:09.862109Z"
    },
    "papermill": {
     "duration": 0.175955,
     "end_time": "2024-10-04T12:57:09.865484",
     "exception": false,
     "start_time": "2024-10-04T12:57:09.689529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_ids': Array([[    2,   109, 14357, ...,     0,     0,     0],\n",
      "       [    2,   109, 14357, ...,     0,     0,     0]], dtype=int32), 'padding_mask': Array([[ True,  True,  True, ..., False, False, False],\n",
      "       [ True,  True,  True, ..., False, False, False]], dtype=bool)} [[   109  14357 235292 ...      0      0      0]\n",
      " [   109  14357 235292 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "x, y, sample_weight = gemma_causal_lm.preprocessor(data[0:2])\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5bc586",
   "metadata": {
    "papermill": {
     "duration": 0.009625,
     "end_time": "2024-10-04T12:57:09.885023",
     "exception": false,
     "start_time": "2024-10-04T12:57:09.875398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `gemma_causal_lm.preprocessor(data[0:2])`: This line calls the `preprocessor` method of the `gemma_causal_lm` object, passing the first two elements of the `data` list as input. The `preprocessor` method is likely responsible for preprocessing the input data into a format suitable for the language model. It might involve tasks such as tokenization, normalization, and encoding.\n",
    "- `x, y = gemma_causal_lm.preprocessor(data[0:2])`: This line unpacks the return value of the `preprocessor` method into two variables, `x` and `y`. The `x` variable likely represents the input features to the model, while the `y` variable represents the corresponding target labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e051bbe",
   "metadata": {
    "papermill": {
     "duration": 0.009357,
     "end_time": "2024-10-04T12:57:09.903888",
     "exception": false,
     "start_time": "2024-10-04T12:57:09.894531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-Tuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf31713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:57:09.925497Z",
     "iopub.status.busy": "2024-10-04T12:57:09.924737Z",
     "iopub.status.idle": "2024-10-04T12:57:10.196782Z",
     "shell.execute_reply": "2024-10-04T12:57:10.195905Z"
    },
    "papermill": {
     "duration": 0.284962,
     "end_time": "2024-10-04T12:57:10.199175",
     "exception": false,
     "start_time": "2024-10-04T12:57:09.914213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d8b88",
   "metadata": {
    "papermill": {
     "duration": 0.009261,
     "end_time": "2024-10-04T12:57:10.218669",
     "exception": false,
     "start_time": "2024-10-04T12:57:10.209408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)`: This line calls the `enable_lora` method of the `backbone` attribute of the `gemma_causal_lm` object, passing the `rank` parameter with the value `Config.lora_rank`\n",
    "- This code enables Low-Rank Adaptation (LoRA) for the `backbone` component of the `gemma_causal_lm` model. LoRA is a technique that allows for fine-tuning a pre-trained model on a smaller dataset while keeping the original model parameters mostly frozen. This can be beneficial in scenarios where the available training data is limited or the model is very large.\n",
    "- The `rank` parameter specifies the rank of the low-rank matrices that will be introduced into the model. A higher rank generally allows for more flexibility but also increases the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0456471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:57:10.238513Z",
     "iopub.status.busy": "2024-10-04T12:57:10.238161Z",
     "iopub.status.idle": "2024-10-04T12:57:10.269882Z",
     "shell.execute_reply": "2024-10-04T12:57:10.269031Z"
    },
    "papermill": {
     "duration": 0.044108,
     "end_time": "2024-10-04T12:57:10.271883",
     "exception": false,
     "start_time": "2024-10-04T12:57:10.227775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_causal_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f22d9d",
   "metadata": {
    "papermill": {
     "duration": 0.010117,
     "end_time": "2024-10-04T12:57:10.292367",
     "exception": false,
     "start_time": "2024-10-04T12:57:10.282250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df7af2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T12:57:10.315769Z",
     "iopub.status.busy": "2024-10-04T12:57:10.315263Z",
     "iopub.status.idle": "2024-10-04T13:11:31.876867Z",
     "shell.execute_reply": "2024-10-04T13:11:31.876061Z"
    },
    "papermill": {
     "duration": 861.574864,
     "end_time": "2024-10-04T13:11:31.878751",
     "exception": false,
     "start_time": "2024-10-04T12:57:10.303887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 991ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.5409\n",
      "Epoch 2/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 806ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.7803\n",
      "Epoch 3/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.8559\n",
      "Epoch 4/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0239 - sparse_categorical_accuracy: 0.8713\n",
      "Epoch 5/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.8915\n",
      "Epoch 6/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.8990\n",
      "Epoch 7/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9077\n",
      "Epoch 8/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9264\n",
      "Epoch 9/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9428\n"
     ]
    }
   ],
   "source": [
    "#set sequence length cf. config (512)\n",
    "gemma_causal_lm.preprocessor.sequence_length = Config.sequence_length \n",
    "\n",
    "# Compile the model with loss, optimizer, and metric\n",
    "gemma_causal_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=Config.learning_rate),\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train model\n",
    "gemma_causal_lm.fit(data, epochs=Config.epochs, batch_size=Config.batch_size)\n",
    "\n",
    "gemma_cg = GemmaCG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76cf5e",
   "metadata": {
    "papermill": {
     "duration": 0.073177,
     "end_time": "2024-10-04T13:11:32.062870",
     "exception": false,
     "start_time": "2024-10-04T13:11:31.989693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Known Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db255d7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:11:32.208773Z",
     "iopub.status.busy": "2024-10-04T13:11:32.208391Z",
     "iopub.status.idle": "2024-10-04T13:11:32.216470Z",
     "shell.execute_reply": "2024-10-04T13:11:32.215559Z"
    },
    "papermill": {
     "duration": 0.083186,
     "end_time": "2024-10-04T13:11:32.218326",
     "exception": false,
     "start_time": "2024-10-04T13:11:32.135140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language                                               Spanish\n",
       "Culture                                               Hispanic\n",
       "Greetings                                          ¿Cómo estás\n",
       "prompt       \\n\\nLanguage:\\nSpanish\\n\\nCulture:\\nHispanic\\n...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5ac646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:11:32.364793Z",
     "iopub.status.busy": "2024-10-04T13:11:32.364231Z",
     "iopub.status.idle": "2024-10-04T13:11:47.520883Z",
     "shell.execute_reply": "2024-10-04T13:11:47.519921Z"
    },
    "papermill": {
     "duration": 15.232444,
     "end_time": "2024-10-04T13:11:47.523059",
     "exception": false,
     "start_time": "2024-10-04T13:11:32.290615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Language:</font>**\n",
       "Spanish\n",
       "\n",
       "**<font color='red'>Culture:</font>**\n",
       "Hispanic\n",
       "\n",
       "**<font color='green'>Greetings:</font>**\n",
       "¿Cómo estás"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = df.iloc[1]\n",
    "gemma_cg.query(row.Language,row.Culture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c596d1e",
   "metadata": {
    "papermill": {
     "duration": 0.072889,
     "end_time": "2024-10-04T13:11:47.669445",
     "exception": false,
     "start_time": "2024-10-04T13:11:47.596556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4cf740d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:11:47.818199Z",
     "iopub.status.busy": "2024-10-04T13:11:47.817707Z",
     "iopub.status.idle": "2024-10-04T13:11:48.243433Z",
     "shell.execute_reply": "2024-10-04T13:11:48.242433Z"
    },
    "papermill": {
     "duration": 0.502069,
     "end_time": "2024-10-04T13:11:48.245439",
     "exception": false,
     "start_time": "2024-10-04T13:11:47.743370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Language:</font>**\n",
       "Malay\n",
       "\n",
       "**<font color='red'>Culture:</font>**\n",
       "Malay\n",
       "\n",
       "**<font color='green'>Greetings:</font>**\n",
       "Kau mana"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Language = \"Malay\"\n",
    "Culture = \"Malay\"\n",
    "gemma_cg.query(Language,Culture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd452a88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:11:48.394797Z",
     "iopub.status.busy": "2024-10-04T13:11:48.394085Z",
     "iopub.status.idle": "2024-10-04T13:12:23.736259Z",
     "shell.execute_reply": "2024-10-04T13:12:23.735348Z"
    },
    "papermill": {
     "duration": 35.41903,
     "end_time": "2024-10-04T13:12:23.738650",
     "exception": false,
     "start_time": "2024-10-04T13:11:48.319620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preset_dir = \".\\gemma2_2b_en_cultural_greetings\"\n",
    "gemma_causal_lm.save_to_preset(preset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8642d",
   "metadata": {
    "papermill": {
     "duration": 0.092668,
     "end_time": "2024-10-04T13:12:35.428004",
     "exception": false,
     "start_time": "2024-10-04T13:12:35.335336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Acknowledgements:\n",
    "\n",
    "Gabriel Preda https://www.kaggle.com/code/gpreda/fine-tuning-gemma-2-model-using-lora-and-keras/notebook\n",
    "\n",
    "Marilia Prata https://www.kaggle.com/code/mpwolke/global-communication-gemma2keras"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9690815,
     "sourceId": 85416,
     "sourceType": "competition"
    },
    {
     "datasetId": 5810993,
     "sourceId": 9544562,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72244,
     "sourceId": 85984,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1059.12953,
   "end_time": "2024-10-04T13:12:39.044432",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-04T12:54:59.914902",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
