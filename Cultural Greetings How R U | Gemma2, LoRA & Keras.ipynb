{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181d4546",
   "metadata": {
    "papermill": {
     "duration": 0.008706,
     "end_time": "2024-10-04T13:37:35.973617",
     "exception": false,
     "start_time": "2024-10-04T13:37:35.964911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Wagtail_Gemma_Blog_social_card_te.2e16d0ba.fill-1200x600.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34cc31",
   "metadata": {
    "papermill": {
     "duration": 0.007789,
     "end_time": "2024-10-04T13:37:35.989390",
     "exception": false,
     "start_time": "2024-10-04T13:37:35.981601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How Are You\n",
    "Gemma 2 will be fine-tunned using LoRA for greetings in different languages and cultures. In this notebook our focus will be **How Are You** greeting. Keras will be used with Gemma 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace90de",
   "metadata": {
    "papermill": {
     "duration": 0.009303,
     "end_time": "2024-10-04T13:37:36.006406",
     "exception": false,
     "start_time": "2024-10-04T13:37:35.997103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71a472d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:37:36.023836Z",
     "iopub.status.busy": "2024-10-04T13:37:36.023013Z",
     "iopub.status.idle": "2024-10-04T13:38:13.665056Z",
     "shell.execute_reply": "2024-10-04T13:38:13.663833Z"
    },
    "papermill": {
     "duration": 37.653351,
     "end_time": "2024-10-04T13:38:13.667597",
     "exception": false,
     "start_time": "2024-10-04T13:37:36.014246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "!pip install -q -U kagglehub --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc6f16",
   "metadata": {
    "papermill": {
     "duration": 0.007567,
     "end_time": "2024-10-04T13:38:13.683274",
     "exception": false,
     "start_time": "2024-10-04T13:38:13.675707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0877741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:38:13.700424Z",
     "iopub.status.busy": "2024-10-04T13:38:13.699742Z",
     "iopub.status.idle": "2024-10-04T13:38:27.685523Z",
     "shell.execute_reply": "2024-10-04T13:38:27.684711Z"
    },
    "papermill": {
     "duration": 13.996968,
     "end_time": "2024-10-04T13:38:27.687884",
     "exception": false,
     "start_time": "2024-10-04T13:38:13.690916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"\"\n",
    "import keras\n",
    "import keras_nlp\n",
    "import kagglehub\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas() # progress bar for pandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bd76b",
   "metadata": {
    "papermill": {
     "duration": 0.007698,
     "end_time": "2024-10-04T13:38:27.703859",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.696161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8e3d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:38:27.720868Z",
     "iopub.status.busy": "2024-10-04T13:38:27.720348Z",
     "iopub.status.idle": "2024-10-04T13:38:27.725458Z",
     "shell.execute_reply": "2024-10-04T13:38:27.724590Z"
    },
    "papermill": {
     "duration": 0.015736,
     "end_time": "2024-10-04T13:38:27.727323",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.711587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 42\n",
    "    dataset_path = \"/kaggle/input/cultural-greetings\"\n",
    "    preset = \"gemma2_2b_en\" # name of pretrained Gemma 2\n",
    "    sequence_length = 512 # max size of input sequence for training\n",
    "    batch_size = 1 # size of the input batch in training\n",
    "    lora_rank = 4 # rank for LoRA, higher means more trainable parameters\n",
    "    learning_rate=8e-5 # learning rate used in train\n",
    "    epochs = 10 # number of epochs to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07a1756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:38:27.743649Z",
     "iopub.status.busy": "2024-10-04T13:38:27.743358Z",
     "iopub.status.idle": "2024-10-04T13:38:27.747706Z",
     "shell.execute_reply": "2024-10-04T13:38:27.746859Z"
    },
    "papermill": {
     "duration": 0.014561,
     "end_time": "2024-10-04T13:38:27.749502",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.734941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da32f9",
   "metadata": {
    "papermill": {
     "duration": 0.007398,
     "end_time": "2024-10-04T13:38:27.764775",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.757377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73bbc31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:38:27.781358Z",
     "iopub.status.busy": "2024-10-04T13:38:27.781028Z",
     "iopub.status.idle": "2024-10-04T13:38:27.806972Z",
     "shell.execute_reply": "2024-10-04T13:38:27.806112Z"
    },
    "papermill": {
     "duration": 0.03641,
     "end_time": "2024-10-04T13:38:27.808851",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.772441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Greetings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Western</td>\n",
       "      <td>How are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>¿Cómo estás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "      <td>Comment ça va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>Wie geht's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Come stai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language   Culture      Greetings\n",
       "0  English   Western    How are you\n",
       "1  Spanish  Hispanic    ¿Cómo estás\n",
       "2   French    French  Comment ça va\n",
       "3   German  Germanic     Wie geht's\n",
       "4  Italian   Italian      Come stai"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{Config.dataset_path}/train_how_are_you.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21eac6a",
   "metadata": {
    "papermill": {
     "duration": 0.007805,
     "end_time": "2024-10-04T13:38:27.824855",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.817050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Template Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf89299c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:38:27.842270Z",
     "iopub.status.busy": "2024-10-04T13:38:27.841564Z",
     "iopub.status.idle": "2024-10-04T13:38:27.851065Z",
     "shell.execute_reply": "2024-10-04T13:38:27.850268Z"
    },
    "papermill": {
     "duration": 0.020126,
     "end_time": "2024-10-04T13:38:27.852957",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.832831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\\n\\nLanguage:\\n{Language}\\n\\nCulture:\\n{Culture}\\n\\nGreetings:\\n{Greetings}\"\n",
    "df[\"prompt\"] = df.apply(lambda row: template.format(Language=row.Language,\n",
    "                                                             Culture=row.Culture,\n",
    "                                                             Greetings=row.Greetings), axis=1)\n",
    "data = df.prompt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef1fdfd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:38:27.871083Z",
     "iopub.status.busy": "2024-10-04T13:38:27.870807Z",
     "iopub.status.idle": "2024-10-04T13:38:27.876008Z",
     "shell.execute_reply": "2024-10-04T13:38:27.875040Z"
    },
    "papermill": {
     "duration": 0.016631,
     "end_time": "2024-10-04T13:38:27.877900",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.861269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Language\", \"Culture\", \"Greetings\"], [\"blue\", \"red\", \"green\"]):\n",
    "        text = text.replace(f\"\\n\\n{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406f00f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:38:27.895442Z",
     "iopub.status.busy": "2024-10-04T13:38:27.894949Z",
     "iopub.status.idle": "2024-10-04T13:39:26.873572Z",
     "shell.execute_reply": "2024-10-04T13:39:26.872581Z"
    },
    "papermill": {
     "duration": 58.989925,
     "end_time": "2024-10-04T13:39:26.875968",
     "exception": false,
     "start_time": "2024-10-04T13:38:27.886043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "gemma_causal_lm = keras_nlp.models.GemmaCausalLM.from_preset(Config.preset)\n",
    "\n",
    "#The code creates a causal language model named gemma_causal_lm using a \n",
    "#pre-defined configuration specified in Config.preset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1696e9f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:39:26.893636Z",
     "iopub.status.busy": "2024-10-04T13:39:26.893309Z",
     "iopub.status.idle": "2024-10-04T13:39:26.924792Z",
     "shell.execute_reply": "2024-10-04T13:39:26.923951Z"
    },
    "papermill": {
     "duration": 0.042362,
     "end_time": "2024-10-04T13:39:26.926683",
     "exception": false,
     "start_time": "2024-10-04T13:39:26.884321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_causal_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41fe55",
   "metadata": {
    "papermill": {
     "duration": 0.00891,
     "end_time": "2024-10-04T13:39:26.944779",
     "exception": false,
     "start_time": "2024-10-04T13:39:26.935869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gemma Cultural Greetings Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b5ef787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:39:26.964083Z",
     "iopub.status.busy": "2024-10-04T13:39:26.963791Z",
     "iopub.status.idle": "2024-10-04T13:39:26.969624Z",
     "shell.execute_reply": "2024-10-04T13:39:26.968776Z"
    },
    "papermill": {
     "duration": 0.017633,
     "end_time": "2024-10-04T13:39:26.971450",
     "exception": false,
     "start_time": "2024-10-04T13:39:26.953817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GemmaCG:\n",
    "    def __init__(self, max_length=512):\n",
    "        self.max_length = max_length\n",
    "        self.prompt = template\n",
    "        self.gemma_causal_lm = gemma_causal_lm\n",
    "        \n",
    "    def query(self, Language, Culture):\n",
    "        response = self.gemma_causal_lm.generate(\n",
    "            self.prompt.format(\n",
    "                Language=Language,\n",
    "                Culture=Culture,\n",
    "                Greetings=\"\"), \n",
    "            max_length=self.max_length)\n",
    "        display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a3637",
   "metadata": {
    "papermill": {
     "duration": 0.008816,
     "end_time": "2024-10-04T13:39:26.989183",
     "exception": false,
     "start_time": "2024-10-04T13:39:26.980367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e2e1d35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:39:27.008619Z",
     "iopub.status.busy": "2024-10-04T13:39:27.008328Z",
     "iopub.status.idle": "2024-10-04T13:39:27.171906Z",
     "shell.execute_reply": "2024-10-04T13:39:27.170728Z"
    },
    "papermill": {
     "duration": 0.175951,
     "end_time": "2024-10-04T13:39:27.174215",
     "exception": false,
     "start_time": "2024-10-04T13:39:26.998264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_ids': Array([[    2,   109, 14357, ...,     0,     0,     0],\n",
      "       [    2,   109, 14357, ...,     0,     0,     0]], dtype=int32), 'padding_mask': Array([[ True,  True,  True, ..., False, False, False],\n",
      "       [ True,  True,  True, ..., False, False, False]], dtype=bool)} [[   109  14357 235292 ...      0      0      0]\n",
      " [   109  14357 235292 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "x, y, sample_weight = gemma_causal_lm.preprocessor(data[0:2])\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ae602",
   "metadata": {
    "papermill": {
     "duration": 0.009226,
     "end_time": "2024-10-04T13:39:27.193075",
     "exception": false,
     "start_time": "2024-10-04T13:39:27.183849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `gemma_causal_lm.preprocessor(data[0:2])`: This line calls the `preprocessor` method of the `gemma_causal_lm` object, passing the first two elements of the `data` list as input. The `preprocessor` method is likely responsible for preprocessing the input data into a format suitable for the language model. It might involve tasks such as tokenization, normalization, and encoding.\n",
    "- `x, y = gemma_causal_lm.preprocessor(data[0:2])`: This line unpacks the return value of the `preprocessor` method into two variables, `x` and `y`. The `x` variable likely represents the input features to the model, while the `y` variable represents the corresponding target labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca154d6",
   "metadata": {
    "papermill": {
     "duration": 0.009298,
     "end_time": "2024-10-04T13:39:27.211437",
     "exception": false,
     "start_time": "2024-10-04T13:39:27.202139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-Tuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c9efba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:39:27.231058Z",
     "iopub.status.busy": "2024-10-04T13:39:27.230732Z",
     "iopub.status.idle": "2024-10-04T13:39:27.499985Z",
     "shell.execute_reply": "2024-10-04T13:39:27.499174Z"
    },
    "papermill": {
     "duration": 0.281835,
     "end_time": "2024-10-04T13:39:27.502446",
     "exception": false,
     "start_time": "2024-10-04T13:39:27.220611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ead4dc",
   "metadata": {
    "papermill": {
     "duration": 0.00904,
     "end_time": "2024-10-04T13:39:27.520964",
     "exception": false,
     "start_time": "2024-10-04T13:39:27.511924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)`: This line calls the `enable_lora` method of the `backbone` attribute of the `gemma_causal_lm` object, passing the `rank` parameter with the value `Config.lora_rank`\n",
    "- This code enables Low-Rank Adaptation (LoRA) for the `backbone` component of the `gemma_causal_lm` model. LoRA is a technique that allows for fine-tuning a pre-trained model on a smaller dataset while keeping the original model parameters mostly frozen. This can be beneficial in scenarios where the available training data is limited or the model is very large.\n",
    "- The `rank` parameter specifies the rank of the low-rank matrices that will be introduced into the model. A higher rank generally allows for more flexibility but also increases the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3afc83a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:39:27.540753Z",
     "iopub.status.busy": "2024-10-04T13:39:27.540409Z",
     "iopub.status.idle": "2024-10-04T13:39:27.572096Z",
     "shell.execute_reply": "2024-10-04T13:39:27.571247Z"
    },
    "papermill": {
     "duration": 0.043864,
     "end_time": "2024-10-04T13:39:27.573975",
     "exception": false,
     "start_time": "2024-10-04T13:39:27.530111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_causal_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19debe09",
   "metadata": {
    "papermill": {
     "duration": 0.01021,
     "end_time": "2024-10-04T13:39:27.594680",
     "exception": false,
     "start_time": "2024-10-04T13:39:27.584470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d930aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:39:27.616904Z",
     "iopub.status.busy": "2024-10-04T13:39:27.616362Z",
     "iopub.status.idle": "2024-10-04T13:53:49.780308Z",
     "shell.execute_reply": "2024-10-04T13:53:49.779361Z"
    },
    "papermill": {
     "duration": 862.177627,
     "end_time": "2024-10-04T13:53:49.782699",
     "exception": false,
     "start_time": "2024-10-04T13:39:27.605072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 990ms/step - loss: 0.1208 - sparse_categorical_accuracy: 0.5363\n",
      "Epoch 2/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 806ms/step - loss: 0.0369 - sparse_categorical_accuracy: 0.7793\n",
      "Epoch 3/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0262 - sparse_categorical_accuracy: 0.8604\n",
      "Epoch 4/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.8736\n",
      "Epoch 5/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.8920\n",
      "Epoch 6/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9022\n",
      "Epoch 7/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0163 - sparse_categorical_accuracy: 0.9108\n",
      "Epoch 8/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0144 - sparse_categorical_accuracy: 0.9285\n",
      "Epoch 9/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9383\n",
      "Epoch 10/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 789ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9430\n"
     ]
    }
   ],
   "source": [
    "#set sequence length cf. config (512)\n",
    "gemma_causal_lm.preprocessor.sequence_length = Config.sequence_length \n",
    "\n",
    "# Compile the model with loss, optimizer, and metric\n",
    "gemma_causal_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=Config.learning_rate),\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train model\n",
    "gemma_causal_lm.fit(data, epochs=Config.epochs, batch_size=Config.batch_size)\n",
    "\n",
    "gemma_cg = GemmaCG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d761871",
   "metadata": {
    "papermill": {
     "duration": 0.093679,
     "end_time": "2024-10-04T13:53:49.973838",
     "exception": false,
     "start_time": "2024-10-04T13:53:49.880159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Known Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e84df033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:53:50.173707Z",
     "iopub.status.busy": "2024-10-04T13:53:50.173286Z",
     "iopub.status.idle": "2024-10-04T13:53:50.182321Z",
     "shell.execute_reply": "2024-10-04T13:53:50.181160Z"
    },
    "papermill": {
     "duration": 0.111597,
     "end_time": "2024-10-04T13:53:50.184841",
     "exception": false,
     "start_time": "2024-10-04T13:53:50.073244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language                                               Spanish\n",
       "Culture                                               Hispanic\n",
       "Greetings                                          ¿Cómo estás\n",
       "prompt       \\n\\nLanguage:\\nSpanish\\n\\nCulture:\\nHispanic\\n...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a30c52a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:53:50.369801Z",
     "iopub.status.busy": "2024-10-04T13:53:50.369031Z",
     "iopub.status.idle": "2024-10-04T13:54:06.286383Z",
     "shell.execute_reply": "2024-10-04T13:54:06.285384Z"
    },
    "papermill": {
     "duration": 16.007317,
     "end_time": "2024-10-04T13:54:06.288340",
     "exception": false,
     "start_time": "2024-10-04T13:53:50.281023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Language:</font>**\n",
       "Spanish\n",
       "\n",
       "**<font color='red'>Culture:</font>**\n",
       "Hispanic\n",
       "\n",
       "**<font color='green'>Greetings:</font>**\n",
       "¿Cómo estás"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = df.iloc[1]\n",
    "gemma_cg.query(row.Language,row.Culture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b98d58",
   "metadata": {
    "papermill": {
     "duration": 0.085208,
     "end_time": "2024-10-04T13:54:06.460556",
     "exception": false,
     "start_time": "2024-10-04T13:54:06.375348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf49d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:54:06.634186Z",
     "iopub.status.busy": "2024-10-04T13:54:06.633794Z",
     "iopub.status.idle": "2024-10-04T13:54:07.057433Z",
     "shell.execute_reply": "2024-10-04T13:54:07.056495Z"
    },
    "papermill": {
     "duration": 0.512607,
     "end_time": "2024-10-04T13:54:07.059458",
     "exception": false,
     "start_time": "2024-10-04T13:54:06.546851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Language:</font>**\n",
       "Malay\n",
       "\n",
       "**<font color='red'>Culture:</font>**\n",
       "Malay\n",
       "\n",
       "**<font color='green'>Greetings:</font>**\n",
       "Kau mana"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Language = \"Malay\"\n",
    "Culture = \"Malay\"\n",
    "gemma_cg.query(Language,Culture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07d76dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:54:07.234166Z",
     "iopub.status.busy": "2024-10-04T13:54:07.233807Z",
     "iopub.status.idle": "2024-10-04T13:54:45.484286Z",
     "shell.execute_reply": "2024-10-04T13:54:45.483153Z"
    },
    "papermill": {
     "duration": 38.339881,
     "end_time": "2024-10-04T13:54:45.486612",
     "exception": false,
     "start_time": "2024-10-04T13:54:07.146731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preset_dir = \".\\gemma2_2b_en_cultural_greetings\"\n",
    "gemma_causal_lm.save_to_preset(preset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15897b5",
   "metadata": {
    "papermill": {
     "duration": 0.170337,
     "end_time": "2024-10-04T13:54:53.813143",
     "exception": false,
     "start_time": "2024-10-04T13:54:53.642806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Acknowledgements:\n",
    "\n",
    "Gabriel Preda https://www.kaggle.com/code/gpreda/fine-tuning-gemma-2-model-using-lora-and-keras/notebook\n",
    "\n",
    "Marilia Prata https://www.kaggle.com/code/mpwolke/global-communication-gemma2keras"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9690815,
     "sourceId": 85416,
     "sourceType": "competition"
    },
    {
     "datasetId": 5810993,
     "sourceId": 9544562,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72244,
     "sourceId": 85984,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1044.190856,
   "end_time": "2024-10-04T13:54:57.361597",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-04T13:37:33.170741",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
