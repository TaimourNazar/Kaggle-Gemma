{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ecc756d",
   "metadata": {
    "papermill": {
     "duration": 0.008512,
     "end_time": "2024-10-07T10:23:58.307353",
     "exception": false,
     "start_time": "2024-10-07T10:23:58.298841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Wagtail_Gemma_Blog_social_card_te.2e16d0ba.fill-1200x600.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63821d90",
   "metadata": {
    "papermill": {
     "duration": 0.007483,
     "end_time": "2024-10-07T10:23:58.322742",
     "exception": false,
     "start_time": "2024-10-07T10:23:58.315259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How Are You\n",
    "Gemma 2 will be fine-tunned using LoRA for greetings in different languages and cultures. In this notebook our focus will be **How Are You** greeting. Keras will be used with Gemma 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77daf263",
   "metadata": {
    "papermill": {
     "duration": 0.008606,
     "end_time": "2024-10-07T10:23:58.339096",
     "exception": false,
     "start_time": "2024-10-07T10:23:58.330490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68925b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:23:58.356317Z",
     "iopub.status.busy": "2024-10-07T10:23:58.355904Z",
     "iopub.status.idle": "2024-10-07T10:24:36.189650Z",
     "shell.execute_reply": "2024-10-07T10:24:36.188530Z"
    },
    "papermill": {
     "duration": 37.84521,
     "end_time": "2024-10-07T10:24:36.192042",
     "exception": false,
     "start_time": "2024-10-07T10:23:58.346832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "!pip install -q -U kagglehub --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceececb",
   "metadata": {
    "papermill": {
     "duration": 0.007548,
     "end_time": "2024-10-07T10:24:36.207696",
     "exception": false,
     "start_time": "2024-10-07T10:24:36.200148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8492f85a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:24:36.224817Z",
     "iopub.status.busy": "2024-10-07T10:24:36.224423Z",
     "iopub.status.idle": "2024-10-07T10:24:49.946172Z",
     "shell.execute_reply": "2024-10-07T10:24:49.945390Z"
    },
    "papermill": {
     "duration": 13.733056,
     "end_time": "2024-10-07T10:24:49.948510",
     "exception": false,
     "start_time": "2024-10-07T10:24:36.215454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"\"\n",
    "import keras\n",
    "import keras_nlp\n",
    "import kagglehub\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas() # progress bar for pandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b76509",
   "metadata": {
    "papermill": {
     "duration": 0.007822,
     "end_time": "2024-10-07T10:24:49.964457",
     "exception": false,
     "start_time": "2024-10-07T10:24:49.956635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58efbe38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:24:49.981660Z",
     "iopub.status.busy": "2024-10-07T10:24:49.981023Z",
     "iopub.status.idle": "2024-10-07T10:24:49.986530Z",
     "shell.execute_reply": "2024-10-07T10:24:49.985672Z"
    },
    "papermill": {
     "duration": 0.016413,
     "end_time": "2024-10-07T10:24:49.988554",
     "exception": false,
     "start_time": "2024-10-07T10:24:49.972141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 42\n",
    "    dataset_path = \"/kaggle/input/cultural-greetings\"\n",
    "    preset = \"gemma2_2b_en\" # name of pretrained Gemma 2\n",
    "    sequence_length = 512 # max size of input sequence for training\n",
    "    batch_size = 1 # size of the input batch in training\n",
    "    lora_rank = 4 # rank for LoRA, higher means more trainable parameters\n",
    "    learning_rate=8e-5 # learning rate used in train\n",
    "    epochs = 10 # number of epochs to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1c640a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:24:50.006066Z",
     "iopub.status.busy": "2024-10-07T10:24:50.005185Z",
     "iopub.status.idle": "2024-10-07T10:24:50.010304Z",
     "shell.execute_reply": "2024-10-07T10:24:50.009425Z"
    },
    "papermill": {
     "duration": 0.015632,
     "end_time": "2024-10-07T10:24:50.012183",
     "exception": false,
     "start_time": "2024-10-07T10:24:49.996551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ff711",
   "metadata": {
    "papermill": {
     "duration": 0.00766,
     "end_time": "2024-10-07T10:24:50.027786",
     "exception": false,
     "start_time": "2024-10-07T10:24:50.020126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75dca1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:24:50.044712Z",
     "iopub.status.busy": "2024-10-07T10:24:50.044347Z",
     "iopub.status.idle": "2024-10-07T10:24:50.084547Z",
     "shell.execute_reply": "2024-10-07T10:24:50.083566Z"
    },
    "papermill": {
     "duration": 0.051207,
     "end_time": "2024-10-07T10:24:50.086733",
     "exception": false,
     "start_time": "2024-10-07T10:24:50.035526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Greetings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Western</td>\n",
       "      <td>How are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>¿Cómo estás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French</td>\n",
       "      <td>French</td>\n",
       "      <td>Comment ça va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>Wie geht's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italian</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Come stai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language   Culture      Greetings\n",
       "0  English   Western    How are you\n",
       "1  Spanish  Hispanic    ¿Cómo estás\n",
       "2   French    French  Comment ça va\n",
       "3   German  Germanic     Wie geht's\n",
       "4  Italian   Italian      Come stai"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{Config.dataset_path}/train_how_are_you.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c550e",
   "metadata": {
    "papermill": {
     "duration": 0.007835,
     "end_time": "2024-10-07T10:24:50.102774",
     "exception": false,
     "start_time": "2024-10-07T10:24:50.094939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Template Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dad4345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:24:50.120053Z",
     "iopub.status.busy": "2024-10-07T10:24:50.119723Z",
     "iopub.status.idle": "2024-10-07T10:24:50.129533Z",
     "shell.execute_reply": "2024-10-07T10:24:50.128726Z"
    },
    "papermill": {
     "duration": 0.020646,
     "end_time": "2024-10-07T10:24:50.131493",
     "exception": false,
     "start_time": "2024-10-07T10:24:50.110847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\\n\\nLanguage:\\n{Language}\\n\\nCulture:\\n{Culture}\\n\\nGreetings:\\n{Greetings}\"\n",
    "df[\"prompt\"] = df.apply(lambda row: template.format(Language=row.Language,\n",
    "                                                             Culture=row.Culture,\n",
    "                                                             Greetings=row.Greetings), axis=1)\n",
    "data = df.prompt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52aad645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:24:50.148838Z",
     "iopub.status.busy": "2024-10-07T10:24:50.148521Z",
     "iopub.status.idle": "2024-10-07T10:24:50.153302Z",
     "shell.execute_reply": "2024-10-07T10:24:50.152468Z"
    },
    "papermill": {
     "duration": 0.015753,
     "end_time": "2024-10-07T10:24:50.155238",
     "exception": false,
     "start_time": "2024-10-07T10:24:50.139485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Language\", \"Culture\", \"Greetings\"], [\"blue\", \"red\", \"green\"]):\n",
    "        text = text.replace(f\"\\n\\n{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57ebaa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:24:50.172122Z",
     "iopub.status.busy": "2024-10-07T10:24:50.171833Z",
     "iopub.status.idle": "2024-10-07T10:25:53.935218Z",
     "shell.execute_reply": "2024-10-07T10:25:53.934420Z"
    },
    "papermill": {
     "duration": 63.774382,
     "end_time": "2024-10-07T10:25:53.937525",
     "exception": false,
     "start_time": "2024-10-07T10:24:50.163143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "gemma_causal_lm = keras_nlp.models.GemmaCausalLM.from_preset(Config.preset)\n",
    "\n",
    "#The code creates a causal language model named gemma_causal_lm using a \n",
    "#pre-defined configuration specified in Config.preset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ea0e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:25:53.955511Z",
     "iopub.status.busy": "2024-10-07T10:25:53.954895Z",
     "iopub.status.idle": "2024-10-07T10:25:53.985540Z",
     "shell.execute_reply": "2024-10-07T10:25:53.984694Z"
    },
    "papermill": {
     "duration": 0.04163,
     "end_time": "2024-10-07T10:25:53.987467",
     "exception": false,
     "start_time": "2024-10-07T10:25:53.945837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_causal_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54775469",
   "metadata": {
    "papermill": {
     "duration": 0.008848,
     "end_time": "2024-10-07T10:25:54.007287",
     "exception": false,
     "start_time": "2024-10-07T10:25:53.998439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gemma Cultural Greetings Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05467089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:25:54.026843Z",
     "iopub.status.busy": "2024-10-07T10:25:54.026535Z",
     "iopub.status.idle": "2024-10-07T10:25:54.032385Z",
     "shell.execute_reply": "2024-10-07T10:25:54.031571Z"
    },
    "papermill": {
     "duration": 0.017915,
     "end_time": "2024-10-07T10:25:54.034267",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.016352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GemmaCG:\n",
    "    def __init__(self, max_length=512):\n",
    "        self.max_length = max_length\n",
    "        self.prompt = template\n",
    "        self.gemma_causal_lm = gemma_causal_lm\n",
    "        \n",
    "    def query(self, Language, Culture):\n",
    "        response = self.gemma_causal_lm.generate(\n",
    "            self.prompt.format(\n",
    "                Language=Language,\n",
    "                Culture=Culture,\n",
    "                Greetings=\"\"), \n",
    "            max_length=self.max_length)\n",
    "        display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5797bb",
   "metadata": {
    "papermill": {
     "duration": 0.008887,
     "end_time": "2024-10-07T10:25:54.052170",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.043283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7afa011c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:25:54.071739Z",
     "iopub.status.busy": "2024-10-07T10:25:54.071456Z",
     "iopub.status.idle": "2024-10-07T10:25:54.242052Z",
     "shell.execute_reply": "2024-10-07T10:25:54.240879Z"
    },
    "papermill": {
     "duration": 0.182848,
     "end_time": "2024-10-07T10:25:54.244309",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.061461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_ids': Array([[    2,   109, 14357, ...,     0,     0,     0],\n",
      "       [    2,   109, 14357, ...,     0,     0,     0]], dtype=int32), 'padding_mask': Array([[ True,  True,  True, ..., False, False, False],\n",
      "       [ True,  True,  True, ..., False, False, False]], dtype=bool)} [[   109  14357 235292 ...      0      0      0]\n",
      " [   109  14357 235292 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "x, y, sample_weight = gemma_causal_lm.preprocessor(data[0:2])\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2710f",
   "metadata": {
    "papermill": {
     "duration": 0.009144,
     "end_time": "2024-10-07T10:25:54.262984",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.253840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `gemma_causal_lm.preprocessor(data[0:2])`: This line calls the `preprocessor` method of the `gemma_causal_lm` object, passing the first two elements of the `data` list as input. The `preprocessor` method is likely responsible for preprocessing the input data into a format suitable for the language model. It might involve tasks such as tokenization, normalization, and encoding.\n",
    "- `x, y = gemma_causal_lm.preprocessor(data[0:2])`: This line unpacks the return value of the `preprocessor` method into two variables, `x` and `y`. The `x` variable likely represents the input features to the model, while the `y` variable represents the corresponding target labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14f8f9",
   "metadata": {
    "papermill": {
     "duration": 0.008944,
     "end_time": "2024-10-07T10:25:54.281020",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.272076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-Tuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1eab8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:25:54.300758Z",
     "iopub.status.busy": "2024-10-07T10:25:54.300405Z",
     "iopub.status.idle": "2024-10-07T10:25:54.581592Z",
     "shell.execute_reply": "2024-10-07T10:25:54.580608Z"
    },
    "papermill": {
     "duration": 0.293856,
     "end_time": "2024-10-07T10:25:54.584046",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.290190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc03b49",
   "metadata": {
    "papermill": {
     "duration": 0.009444,
     "end_time": "2024-10-07T10:25:54.603098",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.593654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `gemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)`: This line calls the `enable_lora` method of the `backbone` attribute of the `gemma_causal_lm` object, passing the `rank` parameter with the value `Config.lora_rank`\n",
    "- This code enables Low-Rank Adaptation (LoRA) for the `backbone` component of the `gemma_causal_lm` model. LoRA is a technique that allows for fine-tuning a pre-trained model on a smaller dataset while keeping the original model parameters mostly frozen. This can be beneficial in scenarios where the available training data is limited or the model is very large.\n",
    "- The `rank` parameter specifies the rank of the low-rank matrices that will be introduced into the model. A higher rank generally allows for more flexibility but also increases the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47399235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:25:54.623259Z",
     "iopub.status.busy": "2024-10-07T10:25:54.622653Z",
     "iopub.status.idle": "2024-10-07T10:25:54.652502Z",
     "shell.execute_reply": "2024-10-07T10:25:54.651576Z"
    },
    "papermill": {
     "duration": 0.04184,
     "end_time": "2024-10-07T10:25:54.654327",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.612487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_causal_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ef611",
   "metadata": {
    "papermill": {
     "duration": 0.010179,
     "end_time": "2024-10-07T10:25:54.675036",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.664857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20926207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:25:54.697546Z",
     "iopub.status.busy": "2024-10-07T10:25:54.696924Z",
     "iopub.status.idle": "2024-10-07T10:39:28.276554Z",
     "shell.execute_reply": "2024-10-07T10:39:28.275620Z"
    },
    "papermill": {
     "duration": 813.593061,
     "end_time": "2024-10-07T10:39:28.278609",
     "exception": false,
     "start_time": "2024-10-07T10:25:54.685548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - loss: 0.1210 - sparse_categorical_accuracy: 0.5361\n",
      "Epoch 2/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 806ms/step - loss: 0.0373 - sparse_categorical_accuracy: 0.7799\n",
      "Epoch 3/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 788ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.8592\n",
      "Epoch 4/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 788ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.8743\n",
      "Epoch 5/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 788ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.8869\n",
      "Epoch 6/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 788ms/step - loss: 0.0197 - sparse_categorical_accuracy: 0.8983\n",
      "Epoch 7/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 788ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9094\n",
      "Epoch 8/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 788ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 788ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9365\n",
      "Epoch 10/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 788ms/step - loss: 0.0126 - sparse_categorical_accuracy: 0.9387\n"
     ]
    }
   ],
   "source": [
    "#set sequence length cf. config (512)\n",
    "gemma_causal_lm.preprocessor.sequence_length = Config.sequence_length \n",
    "\n",
    "# Compile the model with loss, optimizer, and metric\n",
    "gemma_causal_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=Config.learning_rate),\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train model\n",
    "gemma_causal_lm.fit(data, epochs=Config.epochs, batch_size=Config.batch_size)\n",
    "\n",
    "gemma_cg = GemmaCG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d8034",
   "metadata": {
    "papermill": {
     "duration": 0.068851,
     "end_time": "2024-10-07T10:39:28.417827",
     "exception": false,
     "start_time": "2024-10-07T10:39:28.348976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Known Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0f1f23f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:39:28.559131Z",
     "iopub.status.busy": "2024-10-07T10:39:28.558462Z",
     "iopub.status.idle": "2024-10-07T10:39:28.566351Z",
     "shell.execute_reply": "2024-10-07T10:39:28.565421Z"
    },
    "papermill": {
     "duration": 0.081546,
     "end_time": "2024-10-07T10:39:28.568612",
     "exception": false,
     "start_time": "2024-10-07T10:39:28.487066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language                                               Spanish\n",
       "Culture                                               Hispanic\n",
       "Greetings                                          ¿Cómo estás\n",
       "prompt       \\n\\nLanguage:\\nSpanish\\n\\nCulture:\\nHispanic\\n...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41aa842e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:39:28.714054Z",
     "iopub.status.busy": "2024-10-07T10:39:28.713095Z",
     "iopub.status.idle": "2024-10-07T10:39:44.352751Z",
     "shell.execute_reply": "2024-10-07T10:39:44.351767Z"
    },
    "papermill": {
     "duration": 15.714384,
     "end_time": "2024-10-07T10:39:44.354774",
     "exception": false,
     "start_time": "2024-10-07T10:39:28.640390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Language:</font>**\n",
       "Spanish\n",
       "\n",
       "**<font color='red'>Culture:</font>**\n",
       "Hispanic\n",
       "\n",
       "**<font color='green'>Greetings:</font>**\n",
       "¿Cómo estás"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = df.iloc[1]\n",
    "gemma_cg.query(row.Language,row.Culture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b5db8",
   "metadata": {
    "papermill": {
     "duration": 0.070247,
     "end_time": "2024-10-07T10:39:44.495245",
     "exception": false,
     "start_time": "2024-10-07T10:39:44.424998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69762cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:39:44.638294Z",
     "iopub.status.busy": "2024-10-07T10:39:44.637882Z",
     "iopub.status.idle": "2024-10-07T10:39:45.101040Z",
     "shell.execute_reply": "2024-10-07T10:39:45.100093Z"
    },
    "papermill": {
     "duration": 0.537007,
     "end_time": "2024-10-07T10:39:45.103154",
     "exception": false,
     "start_time": "2024-10-07T10:39:44.566147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**<font color='blue'>Language:</font>**\n",
       "Malay\n",
       "\n",
       "**<font color='red'>Culture:</font>**\n",
       "Malay\n",
       "\n",
       "**<font color='green'>Greetings:</font>**\n",
       "Apa khabar"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Language = \"Malay\"\n",
    "Culture = \"Malay\"\n",
    "gemma_cg.query(Language,Culture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19290b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T10:39:45.247627Z",
     "iopub.status.busy": "2024-10-07T10:39:45.247197Z",
     "iopub.status.idle": "2024-10-07T10:40:29.868785Z",
     "shell.execute_reply": "2024-10-07T10:40:29.867884Z"
    },
    "papermill": {
     "duration": 44.696874,
     "end_time": "2024-10-07T10:40:29.871273",
     "exception": false,
     "start_time": "2024-10-07T10:39:45.174399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preset_dir = \".\\gemma2_2b_en_cultural_greetings\"\n",
    "gemma_causal_lm.save_to_preset(preset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd26df",
   "metadata": {
    "papermill": {
     "duration": 0.071211,
     "end_time": "2024-10-07T10:40:30.021791",
     "exception": false,
     "start_time": "2024-10-07T10:40:29.950580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Acknowledgements:\n",
    "\n",
    "Gabriel Preda https://www.kaggle.com/code/gpreda/fine-tuning-gemma-2-model-using-lora-and-keras/notebook\n",
    "\n",
    "Marilia Prata https://www.kaggle.com/code/mpwolke/global-communication-gemma2keras"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9690815,
     "sourceId": 85416,
     "sourceType": "competition"
    },
    {
     "datasetId": 5810993,
     "sourceId": 9566530,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72244,
     "sourceId": 85984,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 997.125589,
   "end_time": "2024-10-07T10:40:32.724143",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-07T10:23:55.598554",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
